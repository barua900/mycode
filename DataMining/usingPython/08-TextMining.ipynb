{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last file with Python mining\n",
    "\n",
    "# importing stuff\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from __future__ import division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I need some specialized functions from NLTK that are not included\n",
    "# by default\n",
    "\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the \"stopwords\" package from NLTK.\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's read data\n",
    "\n",
    "with codecs.open(\"JaneEyre.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jane_eyre = f.read()\n",
    "with codecs.open(\"WutheringHeights.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wuthering_heights = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Processing Data; Checking english stopwords\n",
    "\n",
    "esw = stopwords.words('english')\n",
    "esw.append(\"would\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering tokens (using regular expressions).\n",
    "word_pattern = re.compile(\"^\\w+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a token counter function.\n",
    "\n",
    "def get_text_counter(text):\n",
    "    tokens = WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens = list(map(lambda x: x.lower(), tokens))\n",
    "    tokens = [token for token in tokens if re.match(word_pattern, token) and token not in esw]\n",
    "    return collections.Counter(tokens), len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to calculate the absolute frequency and relative \n",
    "# frequency of the most common words.\n",
    "\n",
    "def make_df(counter, size):\n",
    "    abs_freq = np.array([el[1] for el in counter])\n",
    "    rel_freq = abs_freq / size\n",
    "    index = [el[0] for el in counter]\n",
    "    df = pd.DataFrame(data=np.array([abs_freq, rel_freq]).T, index=index, columns=[\"Absolute frequency\", \"Relative frequency\"])\n",
    "    df.index.name = \"Most common words\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analyzing individual texts\n",
    "\n",
    "# Calculating the most common words of Jane Eyre. This takes a while. \n",
    "# Then displaying the 10 most common.\n",
    "\n",
    "je_counter, je_size = get_text_counter(jane_eyre)\n",
    "make_df(je_counter.most_common(10), je_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the 1000 most common words of Jane Eyre to CSV.\n",
    "\n",
    "je_df = make_df(je_counter.most_common(1000), je_size)\n",
    "je_df.to_csv(\"JE_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the most common words of Wuthering Heights. This also \n",
    "# takes a while. Displaying the 10 most common.\n",
    "\n",
    "wh_counter, wh_size = get_text_counter(wuthering_heights)\n",
    "make_df(wh_counter.most_common(10), wh_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the 1000 most common words of Wuthering Heights to CSV.\n",
    "\n",
    "wh_df = make_df(wh_counter.most_common(1000), wh_size)\n",
    "wh_df.to_csv(\"WH_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's Compare texts\n",
    "\n",
    "# Find the most common words across the two documents.\n",
    "\n",
    "all_counter = wh_counter + je_counter\n",
    "all_df = make_df(wh_counter.most_common(1000), 1)\n",
    "most_common_words = all_df.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a data frame with the word frequency differences.\n",
    "\n",
    "df_data = []\n",
    "for word in most_common_words:\n",
    "    je_c = je_counter.get(word, 0) / je_size\n",
    "    wh_c = wh_counter.get(word, 0) / wh_size\n",
    "    d = abs(je_c - wh_c)\n",
    "    df_data.append([je_c, wh_c, d])\n",
    "dist_df = pd.DataFrame(data=df_data, index=most_common_words,\n",
    "                       columns=[\"Jane Eyre relative frequency\", \"Wuthering Heights relative frequency\",\n",
    "                                \"Relative frequency difference\"])\n",
    "dist_df.index.name = \"Most common words\"\n",
    "dist_df.sort_values(\"Relative frequency difference\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Displaying the most distinctive words.\n",
    "\n",
    "dist_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the full list of distinctive words to a CSV named \"bronte.csv.\"\n",
    "\n",
    "dist_df.to_csv(\"bronte.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
