{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Numpy library to generate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# initialize the weights and bias\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2)\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63  0.52  0.82  0.06  0.28  0.48]\n",
      "[ 0.04  0.03  0.27]\n"
     ]
    }
   ],
   "source": [
    "# let's print the weights and biases for sanity check\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the weights and the biases for the network, let's\n",
    "# compute the output for a given input, x1 and x2.\n",
    "\n",
    "x_1 = 0.5  #input1\n",
    "x_2 = 0.85  # input2\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.797\n"
     ]
    }
   ],
   "source": [
    "# Let's start by computing the weighted sum of the inputs, z_11, at \n",
    "# the first node of the hidden layer\n",
    "\n",
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "\n",
    "print('The weighted sum of the inputs at the first node in the hidden layer is {}'. format(z_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the second node in the hidden      layer is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Next, let's compute the weighted sum of the inputs, z_12, at the \n",
    "# second node of the hidden layer. assign the value of z_12\n",
    "\n",
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "\n",
    "print('The weighted sum of the inputs at the second node in the hidden\\\n",
    "      layer is {}'.format(np.around(z_12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is  0.6893\n"
     ]
    }
   ],
   "source": [
    "# Next, assuming a Sigmoid activation function, let's compute the \n",
    "# activation of the first node, a11, in the hidden layer\n",
    "\n",
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is \\\n",
    " {}'.format(np.around(a_11, decimals = 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the second node in the hidden layer is 0.6203\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the activation of the second node, a12, in the hidden\n",
    "# layer. Assign the value to a_12.\n",
    "\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "\n",
    "print('The activation of the second node in the hidden layer is {}'.\\\n",
    "     format(np.around(a_12, decimals=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 0.7608\n"
     ]
    }
   ],
   "source": [
    "# Print the weighted sum of the inputs at the node in the output layer\n",
    "\n",
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]\n",
    "\n",
    "print('The weighted sum of the inputs at the node in the output layer \\\n",
    "is {}'. format(np.around(z_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1 = 0.5 and x2 = 0.85 is 0.6815\n"
     ]
    }
   ],
   "source": [
    "# Print the activation of the node in the output layer which is \n",
    "# equivalent to the prediction made by the network.\n",
    "\n",
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "\n",
    "print('The output of the network for x1 = 0.5 and x2 = 0.85 is {}'.\\\n",
    "     format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to code an automatic way of making predictions, let's\n",
    "# generalize our network. A general network would take n inputs, would\n",
    "# have many hidden layer, each hidden layer having m nodes, and would\n",
    "# have an output layer. Although the network is showing one hidden layer,\n",
    "# but we will code the network to have many hidden layers. Similarly, \n",
    "# although the network shows an output layer with one code, we will code\n",
    "# the network to have more than one node in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE A NETWORK\n",
    "\n",
    "# Let's start by formally defining the structure of the network\n",
    "\n",
    "n = 2  # number of inputs\n",
    "num_hidden_layers = 2   # number of hidden layres\n",
    "m = [2, 2]  # number of nodes in each hidden layer\n",
    "num_nodes_output = 1  # number of nodes in the output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we define the structure of the network, let's go ahead and initialize\n",
    "# the weights and the biases in the network to random numbers. In order\n",
    "# to be able to initialize the weights and biases to random numbers,\n",
    "# we will need to import the Numpy library.\n",
    "\n",
    "import numpy as np   # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n  # number of nodes in the previous layer\n",
    "\n",
    "network = {}  # initialize network an empty dictionary\n",
    "\n",
    "# Loop through each layer and randomly initialize the weights and biases\n",
    "# associated with each node. Notice how we are adding 1 to the number of\n",
    "# hidden layers in order to include the output layer \n",
    "\n",
    "for layer in range(num_hidden_layers + 1):\n",
    "    #determine name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(node + 1)\n",
    "        num_nodes = m[layer]\n",
    "        \n",
    "    # initialize weights and biases associated with each node in the \n",
    "    # current layer\n",
    "    \n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node + 1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'biases': np.around(np.random.uniform(size=1), deciamls=2),\n",
    "        }\n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network)  # printing network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now with above code, we are able to initialize the weights and biases\n",
    "# pertaining to any network of any number of hidden layers and number of \n",
    "# nodes in each layer. But let's put this code in function so that we\n",
    "# are able to repetitively execute all this code whenever we want to \n",
    "# construct a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden,\\\n",
    "                      num_nodes_output):\n",
    "    num_nodes_previous = num_inputs  # number of nodes in the previous layer\n",
    "    \n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and \n",
    "    # biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output'  # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) #otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer]\n",
    "            \n",
    "        #initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node + 1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous),\\\n",
    "                                    decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "            \n",
    "        num_nodes_previous = num_nodes\n",
    "        \n",
    "    return network  # return the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#USE THE INITIALIZE_NETWORK FUNCTION to create a network list:\n",
    "\n",
    "# 1. takes 5 inputs\n",
    "# 2. has three hidden layers\n",
    "# 3. has 3 nodes in the first layer, 2 nodes in the second layer, and\n",
    "#    3 nodes in the third layer\n",
    "# 4. has 1 node in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([ 0.9 ,  0.75,  0.51,  0.74,  0.13]), 'bias': array([ 0.04])}, 'node_2': {'weights': array([ 0.52,  0.52,  0.26,  0.75,  0.18]), 'bias': array([ 0.2])}, 'node_3': {'weights': array([ 0.53,  0.94,  0.96,  0.81,  0.  ]), 'bias': array([ 0.76])}}, 'layer_2': {'node_1': {'weights': array([ 0.26,  0.53,  0.4 ]), 'bias': array([ 0.22])}, 'node_2': {'weights': array([ 0.39,  0.13,  0.48]), 'bias': array([ 0.16])}}, 'layer_3': {'node_1': {'weights': array([ 0.87,  0.25]), 'bias': array([ 0.78])}, 'node_2': {'weights': array([ 0.97,  0.96]), 'bias': array([ 0.61])}, 'node_3': {'weights': array([ 0.8 ,  0.38]), 'bias': array([ 0.18])}}, 'output': {'node_1': {'weights': array([ 0.92,  0.83,  0.81]), 'bias': array([ 0.3])}}}\n"
     ]
    }
   ],
   "source": [
    "# Call the network small_network.\n",
    "\n",
    "small_network = initialize_network(5, 3, [3, 2, 3], 1)\n",
    "print(small_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE WEIGHTED SUM AT EACH NODE\n",
    "\n",
    "# The weighted sum at each node is computed as the dot product of the \n",
    "# inputs and the weights plus the bias. So let's create a function \n",
    "# called compute_weighted_sum that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [ 0.15  0.74  0.26  0.53  0.01]\n"
     ]
    }
   ],
   "source": [
    "# Let's generate 5 inputs that we can feed to small_network.\n",
    "\n",
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum at the first node in the hidden layer is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use the computed_weighted_sum function to compute the weighted sum\n",
    "# at the first node in the first hidden layer\n",
    "\n",
    "node_weights = small_network['layer_1']['node_1']['weights']\n",
    "node_bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "weighted_sum = compute_weighted_sum(inputs, node_weights, node_bias)\n",
    "print('The weighted sum at the first node in the hidden layer is {}'.\\\n",
    "     format(np.around(weighted_sum)[0], decimals=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE NODE ACTIVATION\n",
    "\n",
    "# Recall that the output of each node is simply a non-linear transformation\n",
    "# of the weighted sum. We use activation functions for this mapping.\n",
    "# Let's use the Sigmoid function as the activation function here. So\n",
    "# let's define a function that takes a weighted sum as input and returns\n",
    "# the non-linear tranformation of the input using the Sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first node in the hidden layer is 0.7784\n"
     ]
    }
   ],
   "source": [
    "# Use the node_activation function to compute the output of the first\n",
    "# node in the first hidden layer.\n",
    "\n",
    "node_output = node_activation(compute_weighted_sum(inputs, node_weights,\\\n",
    "                                                  node_bias))\n",
    "print('The output of the first node in the hidden layer is {}'.\\\n",
    "     format(np.around(node_output[0], decimals=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD PROPAGATION\n",
    "\n",
    "# The final piece of building a neural network that can perform\n",
    "# predictions is to put everything together. So let's creat function\n",
    "# that applies the compute_weighted_sum and node_activation functions\n",
    "# to each node in the network and propagates the data all the way to the\n",
    "# output layer and outputs a prediction for each node in the output layer.\n",
    "\n",
    "\n",
    "# The way we are going to accomplish this is through the following\n",
    "# procedures:\n",
    "\n",
    "#1. Start with the input layer as the input to the first hidden layer.\n",
    "#2. Compute the weighted sum at the nodes of the current layer.\n",
    "#3. Compute the output of the nodes of the current layer.\n",
    "#4. Set the output of the current layer to be the input to the next layer.\n",
    "#5. Move to the next layer in the network.\n",
    "#6. Repeat steps 2 - 4 until we compute the output of the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs)  # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = []\n",
    "        for layer_node in layer_data:\n",
    "            \n",
    "            node_data = layer_data[layer_node]\n",
    "            \n",
    "            # compute the weighted sum and the output of each node at the same time\n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs,\\\n",
    "                                                node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {}\\\n",
    "            is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "            \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "        \n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1            is [0.77839999999999998, 0.75580000000000003, 0.90149999999999997]\n",
      "The outputs of the nodes in hidden layer number 2            is [0.76559999999999995, 0.72999999999999998]\n",
      "The outputs of the nodes in hidden layer number 3            is [0.83599999999999997, 0.88629999999999998, 0.74460000000000004]\n",
      "The predicted value by the network for the given input is 0.9174\n"
     ]
    }
   ],
   "source": [
    "predictions = forward_propagate(small_network, inputs)\n",
    "print('The predicted value by the network for the given input is {}'.\\\n",
    "     format(np.around(predictions[0], decimals=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So we build the code to define a neural network. We can specify the \n",
    "# number of inputs that a neural network can take, the number of hidden\n",
    "# layers as well as the number of nodes in each hidden layer, and the\n",
    "# number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We first use the initialize_network to create our neural network and\n",
    "# define its weights and biases\n",
    "\n",
    "my_network = initialize_network(5, 3, [2, 3, 2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then, for a given input\n",
    "\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1            is [0.88570000000000004, 0.88890000000000002]\n",
      "The outputs of the nodes in hidden layer number 2            is [0.78220000000000001, 0.69650000000000001, 0.74109999999999998]\n",
      "The outputs of the nodes in hidden layer number 3            is [0.86799999999999999, 0.88100000000000001]\n",
      "The predicted values by the network for the given input are [0.8952, 0.82220000000000004, 0.80349999999999999]\n"
     ]
    }
   ],
   "source": [
    "# We compute the network predictions\n",
    "\n",
    "predictions = forward_propagate(my_network, inputs)\n",
    "\n",
    "print('The predicted values by the network for the given input are {}'.\\\n",
    "     format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
